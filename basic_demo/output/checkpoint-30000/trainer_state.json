{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0471204188481675,
  "eval_steps": 1500,
  "global_step": 30000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 3.3816967010498047,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 4.0998,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.492903232574463,
      "learning_rate": 4.966666666666667e-05,
      "loss": 3.6566,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.866041660308838,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.5709,
      "step": 300
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.59262228012085,
      "learning_rate": 4.933333333333334e-05,
      "loss": 3.4934,
      "step": 400
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.921512126922607,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 3.504,
      "step": 500
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.46125602722168,
      "learning_rate": 4.9e-05,
      "loss": 3.4856,
      "step": 600
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.311365604400635,
      "learning_rate": 4.883333333333334e-05,
      "loss": 3.437,
      "step": 700
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.843714714050293,
      "learning_rate": 4.866666666666667e-05,
      "loss": 3.4666,
      "step": 800
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.58450984954834,
      "learning_rate": 4.85e-05,
      "loss": 3.4033,
      "step": 900
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.917341232299805,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 3.4396,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.450716972351074,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 3.4519,
      "step": 1100
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.200622081756592,
      "learning_rate": 4.8e-05,
      "loss": 3.4021,
      "step": 1200
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.147000312805176,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 3.3704,
      "step": 1300
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.344797134399414,
      "learning_rate": 4.766666666666667e-05,
      "loss": 3.3923,
      "step": 1400
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.620858192443848,
      "learning_rate": 4.75e-05,
      "loss": 3.362,
      "step": 1500
    },
    {
      "epoch": 0.05,
      "eval_bleu-4": 0.031654737549697456,
      "eval_rouge-1": 32.466927999999996,
      "eval_rouge-2": 6.2366259999999984,
      "eval_rouge-l": 25.638175999999998,
      "eval_runtime": 11.769,
      "eval_samples_per_second": 4.248,
      "eval_steps_per_second": 0.34,
      "step": 1500
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.857300758361816,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 3.4236,
      "step": 1600
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.49027156829834,
      "learning_rate": 4.716666666666667e-05,
      "loss": 3.3894,
      "step": 1700
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.2672343254089355,
      "learning_rate": 4.7e-05,
      "loss": 3.4092,
      "step": 1800
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.175048828125,
      "learning_rate": 4.683333333333334e-05,
      "loss": 3.3883,
      "step": 1900
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.660699844360352,
      "learning_rate": 4.666666666666667e-05,
      "loss": 3.3732,
      "step": 2000
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.239548683166504,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.423,
      "step": 2100
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.4523725509643555,
      "learning_rate": 4.633333333333333e-05,
      "loss": 3.3937,
      "step": 2200
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.234979629516602,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 3.3742,
      "step": 2300
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.558632850646973,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.3492,
      "step": 2400
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.407913208007812,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 3.3578,
      "step": 2500
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.687345027923584,
      "learning_rate": 4.566666666666667e-05,
      "loss": 3.3791,
      "step": 2600
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.331189155578613,
      "learning_rate": 4.55e-05,
      "loss": 3.4003,
      "step": 2700
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.081035614013672,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 3.3305,
      "step": 2800
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.01138687133789,
      "learning_rate": 4.516666666666667e-05,
      "loss": 3.3775,
      "step": 2900
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.9842681884765625,
      "learning_rate": 4.5e-05,
      "loss": 3.3321,
      "step": 3000
    },
    {
      "epoch": 0.1,
      "eval_bleu-4": 0.03292464521129044,
      "eval_rouge-1": 32.497158000000006,
      "eval_rouge-2": 6.728413999999999,
      "eval_rouge-l": 24.417794,
      "eval_runtime": 31.3243,
      "eval_samples_per_second": 1.596,
      "eval_steps_per_second": 0.128,
      "step": 3000
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.848629474639893,
      "learning_rate": 4.483333333333333e-05,
      "loss": 3.3422,
      "step": 3100
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.374202728271484,
      "learning_rate": 4.466666666666667e-05,
      "loss": 3.3638,
      "step": 3200
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.524794578552246,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.3565,
      "step": 3300
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.606592655181885,
      "learning_rate": 4.433333333333334e-05,
      "loss": 3.3335,
      "step": 3400
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.047088146209717,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 3.3081,
      "step": 3500
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.416216850280762,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.292,
      "step": 3600
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.915158271789551,
      "learning_rate": 4.383333333333334e-05,
      "loss": 3.3277,
      "step": 3700
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.260871887207031,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 3.2913,
      "step": 3800
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.2741007804870605,
      "learning_rate": 4.35e-05,
      "loss": 3.355,
      "step": 3900
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.116850852966309,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 3.3625,
      "step": 4000
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.622319221496582,
      "learning_rate": 4.316666666666667e-05,
      "loss": 3.3179,
      "step": 4100
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.524164199829102,
      "learning_rate": 4.3e-05,
      "loss": 3.3329,
      "step": 4200
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.347012519836426,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 3.3137,
      "step": 4300
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.168367385864258,
      "learning_rate": 4.266666666666667e-05,
      "loss": 3.282,
      "step": 4400
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.58353328704834,
      "learning_rate": 4.25e-05,
      "loss": 3.3071,
      "step": 4500
    },
    {
      "epoch": 0.16,
      "eval_bleu-4": 0.03369212717342125,
      "eval_rouge-1": 31.267053999999995,
      "eval_rouge-2": 6.605848000000001,
      "eval_rouge-l": 24.909687999999996,
      "eval_runtime": 30.8633,
      "eval_samples_per_second": 1.62,
      "eval_steps_per_second": 0.13,
      "step": 4500
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.520147323608398,
      "learning_rate": 4.233333333333334e-05,
      "loss": 3.2983,
      "step": 4600
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.837972164154053,
      "learning_rate": 4.216666666666667e-05,
      "loss": 3.3613,
      "step": 4700
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.7235612869262695,
      "learning_rate": 4.2e-05,
      "loss": 3.3368,
      "step": 4800
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.104629516601562,
      "learning_rate": 4.183333333333334e-05,
      "loss": 3.2952,
      "step": 4900
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.068364143371582,
      "learning_rate": 4.166666666666667e-05,
      "loss": 3.2682,
      "step": 5000
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.032731056213379,
      "learning_rate": 4.15e-05,
      "loss": 3.324,
      "step": 5100
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.817259311676025,
      "learning_rate": 4.133333333333333e-05,
      "loss": 3.2914,
      "step": 5200
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.231662273406982,
      "learning_rate": 4.116666666666667e-05,
      "loss": 3.2458,
      "step": 5300
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.310662269592285,
      "learning_rate": 4.1e-05,
      "loss": 3.2559,
      "step": 5400
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.8040900230407715,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 3.2891,
      "step": 5500
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.116990089416504,
      "learning_rate": 4.066666666666667e-05,
      "loss": 3.2977,
      "step": 5600
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.878244400024414,
      "learning_rate": 4.05e-05,
      "loss": 3.313,
      "step": 5700
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.9786224365234375,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 3.3236,
      "step": 5800
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.404692649841309,
      "learning_rate": 4.016666666666667e-05,
      "loss": 3.2121,
      "step": 5900
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.567892074584961,
      "learning_rate": 4e-05,
      "loss": 3.3709,
      "step": 6000
    },
    {
      "epoch": 0.21,
      "eval_bleu-4": 0.029107160791152983,
      "eval_rouge-1": 31.546764,
      "eval_rouge-2": 6.372103999999999,
      "eval_rouge-l": 23.207274,
      "eval_runtime": 30.9565,
      "eval_samples_per_second": 1.615,
      "eval_steps_per_second": 0.129,
      "step": 6000
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.381339073181152,
      "learning_rate": 3.983333333333333e-05,
      "loss": 3.2622,
      "step": 6100
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.896162033081055,
      "learning_rate": 3.966666666666667e-05,
      "loss": 3.2722,
      "step": 6200
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.553103446960449,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.2732,
      "step": 6300
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.0459885597229,
      "learning_rate": 3.933333333333333e-05,
      "loss": 3.3505,
      "step": 6400
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.475334644317627,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 3.3092,
      "step": 6500
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.8273606300354,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.2961,
      "step": 6600
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.998303413391113,
      "learning_rate": 3.883333333333333e-05,
      "loss": 3.239,
      "step": 6700
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.689953327178955,
      "learning_rate": 3.866666666666667e-05,
      "loss": 3.2813,
      "step": 6800
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.031445503234863,
      "learning_rate": 3.85e-05,
      "loss": 3.2846,
      "step": 6900
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.974882125854492,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 3.2727,
      "step": 7000
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.11702299118042,
      "learning_rate": 3.816666666666667e-05,
      "loss": 3.2796,
      "step": 7100
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.94666862487793,
      "learning_rate": 3.8e-05,
      "loss": 3.2884,
      "step": 7200
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.906581401824951,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 3.2466,
      "step": 7300
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.117607116699219,
      "learning_rate": 3.766666666666667e-05,
      "loss": 3.2519,
      "step": 7400
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.816051006317139,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.227,
      "step": 7500
    },
    {
      "epoch": 0.26,
      "eval_bleu-4": 0.033163205779497586,
      "eval_rouge-1": 32.35561200000001,
      "eval_rouge-2": 7.364516,
      "eval_rouge-l": 24.364030000000003,
      "eval_runtime": 40.4179,
      "eval_samples_per_second": 1.237,
      "eval_steps_per_second": 0.099,
      "step": 7500
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.516470432281494,
      "learning_rate": 3.733333333333334e-05,
      "loss": 3.3064,
      "step": 7600
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.807693958282471,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 3.2524,
      "step": 7700
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.136553764343262,
      "learning_rate": 3.7e-05,
      "loss": 3.2662,
      "step": 7800
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.226905822753906,
      "learning_rate": 3.683333333333334e-05,
      "loss": 3.2655,
      "step": 7900
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.049156188964844,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 3.2609,
      "step": 8000
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.370140075683594,
      "learning_rate": 3.65e-05,
      "loss": 3.2265,
      "step": 8100
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.002985954284668,
      "learning_rate": 3.633333333333333e-05,
      "loss": 3.2796,
      "step": 8200
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.058302402496338,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 3.2594,
      "step": 8300
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.745269775390625,
      "learning_rate": 3.6e-05,
      "loss": 3.2422,
      "step": 8400
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.3970818519592285,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 3.2365,
      "step": 8500
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.398171424865723,
      "learning_rate": 3.566666666666667e-05,
      "loss": 3.2467,
      "step": 8600
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.730616569519043,
      "learning_rate": 3.55e-05,
      "loss": 3.2778,
      "step": 8700
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.915294170379639,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 3.2468,
      "step": 8800
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.6402268409729,
      "learning_rate": 3.516666666666667e-05,
      "loss": 3.2546,
      "step": 8900
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.473834991455078,
      "learning_rate": 3.5e-05,
      "loss": 3.2728,
      "step": 9000
    },
    {
      "epoch": 0.31,
      "eval_bleu-4": 0.03752731284791531,
      "eval_rouge-1": 32.403518,
      "eval_rouge-2": 7.424269999999999,
      "eval_rouge-l": 25.030917999999996,
      "eval_runtime": 10.8787,
      "eval_samples_per_second": 4.596,
      "eval_steps_per_second": 0.368,
      "step": 9000
    },
    {
      "epoch": 0.32,
      "grad_norm": 8.539925575256348,
      "learning_rate": 3.483333333333334e-05,
      "loss": 3.2389,
      "step": 9100
    },
    {
      "epoch": 0.32,
      "grad_norm": 8.227707862854004,
      "learning_rate": 3.466666666666667e-05,
      "loss": 3.2087,
      "step": 9200
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.553668975830078,
      "learning_rate": 3.45e-05,
      "loss": 3.2438,
      "step": 9300
    },
    {
      "epoch": 0.33,
      "grad_norm": 9.049419403076172,
      "learning_rate": 3.433333333333333e-05,
      "loss": 3.2425,
      "step": 9400
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.088829040527344,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 3.1839,
      "step": 9500
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.471137523651123,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.2564,
      "step": 9600
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.96998405456543,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 3.2581,
      "step": 9700
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.347500801086426,
      "learning_rate": 3.366666666666667e-05,
      "loss": 3.2819,
      "step": 9800
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.397418975830078,
      "learning_rate": 3.35e-05,
      "loss": 3.1836,
      "step": 9900
    },
    {
      "epoch": 0.35,
      "grad_norm": 7.614259719848633,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 3.2347,
      "step": 10000
    },
    {
      "epoch": 0.35,
      "grad_norm": 7.910367488861084,
      "learning_rate": 3.316666666666667e-05,
      "loss": 3.2289,
      "step": 10100
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.66641902923584,
      "learning_rate": 3.3e-05,
      "loss": 3.2411,
      "step": 10200
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.076035499572754,
      "learning_rate": 3.283333333333333e-05,
      "loss": 3.2495,
      "step": 10300
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.04578971862793,
      "learning_rate": 3.266666666666667e-05,
      "loss": 3.2357,
      "step": 10400
    },
    {
      "epoch": 0.37,
      "grad_norm": 7.594321250915527,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.2332,
      "step": 10500
    },
    {
      "epoch": 0.37,
      "eval_bleu-4": 0.033763136077845556,
      "eval_rouge-1": 31.116278,
      "eval_rouge-2": 7.358334,
      "eval_rouge-l": 23.518251999999997,
      "eval_runtime": 42.2872,
      "eval_samples_per_second": 1.182,
      "eval_steps_per_second": 0.095,
      "step": 10500
    },
    {
      "epoch": 0.37,
      "grad_norm": 7.974515914916992,
      "learning_rate": 3.233333333333333e-05,
      "loss": 3.2092,
      "step": 10600
    },
    {
      "epoch": 0.37,
      "grad_norm": 8.548613548278809,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 3.2158,
      "step": 10700
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.679333686828613,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.2284,
      "step": 10800
    },
    {
      "epoch": 0.38,
      "grad_norm": 8.283294677734375,
      "learning_rate": 3.183333333333334e-05,
      "loss": 3.2306,
      "step": 10900
    },
    {
      "epoch": 0.38,
      "grad_norm": 8.043553352355957,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 3.1839,
      "step": 11000
    },
    {
      "epoch": 0.39,
      "grad_norm": 8.346972465515137,
      "learning_rate": 3.15e-05,
      "loss": 3.2323,
      "step": 11100
    },
    {
      "epoch": 0.39,
      "grad_norm": 8.319920539855957,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 3.1967,
      "step": 11200
    },
    {
      "epoch": 0.39,
      "grad_norm": 9.384533882141113,
      "learning_rate": 3.116666666666667e-05,
      "loss": 3.2282,
      "step": 11300
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.684137344360352,
      "learning_rate": 3.1e-05,
      "loss": 3.2192,
      "step": 11400
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.533777236938477,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 3.1987,
      "step": 11500
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.364867687225342,
      "learning_rate": 3.066666666666667e-05,
      "loss": 3.2789,
      "step": 11600
    },
    {
      "epoch": 0.41,
      "grad_norm": 9.660798072814941,
      "learning_rate": 3.05e-05,
      "loss": 3.1868,
      "step": 11700
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.859309196472168,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 3.2291,
      "step": 11800
    },
    {
      "epoch": 0.42,
      "grad_norm": 8.283267974853516,
      "learning_rate": 3.016666666666667e-05,
      "loss": 3.1902,
      "step": 11900
    },
    {
      "epoch": 0.42,
      "grad_norm": 8.768928527832031,
      "learning_rate": 3e-05,
      "loss": 3.1888,
      "step": 12000
    },
    {
      "epoch": 0.42,
      "eval_bleu-4": 0.03415489902775122,
      "eval_rouge-1": 32.512648,
      "eval_rouge-2": 8.017550000000002,
      "eval_rouge-l": 24.02753,
      "eval_runtime": 41.5739,
      "eval_samples_per_second": 1.203,
      "eval_steps_per_second": 0.096,
      "step": 12000
    },
    {
      "epoch": 0.42,
      "grad_norm": 8.963590621948242,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 3.1905,
      "step": 12100
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.704070568084717,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 3.1718,
      "step": 12200
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.15146255493164,
      "learning_rate": 2.95e-05,
      "loss": 3.2019,
      "step": 12300
    },
    {
      "epoch": 0.43,
      "grad_norm": 8.576027870178223,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 3.1967,
      "step": 12400
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.116244316101074,
      "learning_rate": 2.916666666666667e-05,
      "loss": 3.2266,
      "step": 12500
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.342940330505371,
      "learning_rate": 2.9e-05,
      "loss": 3.2035,
      "step": 12600
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.910335540771484,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 3.1924,
      "step": 12700
    },
    {
      "epoch": 0.45,
      "grad_norm": 8.136967658996582,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 3.1899,
      "step": 12800
    },
    {
      "epoch": 0.45,
      "grad_norm": 8.597445487976074,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.1844,
      "step": 12900
    },
    {
      "epoch": 0.45,
      "grad_norm": 9.372090339660645,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 3.1722,
      "step": 13000
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.78925609588623,
      "learning_rate": 2.816666666666667e-05,
      "loss": 3.1867,
      "step": 13100
    },
    {
      "epoch": 0.46,
      "grad_norm": 7.877357482910156,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.2138,
      "step": 13200
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.283772468566895,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 3.1759,
      "step": 13300
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.673929214477539,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 3.2233,
      "step": 13400
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.636197090148926,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.2051,
      "step": 13500
    },
    {
      "epoch": 0.47,
      "eval_bleu-4": 0.03415873760849692,
      "eval_rouge-1": 31.901638000000002,
      "eval_rouge-2": 7.6265920000000005,
      "eval_rouge-l": 23.616390000000003,
      "eval_runtime": 42.4581,
      "eval_samples_per_second": 1.178,
      "eval_steps_per_second": 0.094,
      "step": 13500
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.352869033813477,
      "learning_rate": 2.733333333333333e-05,
      "loss": 3.2091,
      "step": 13600
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.096405029296875,
      "learning_rate": 2.716666666666667e-05,
      "loss": 3.2016,
      "step": 13700
    },
    {
      "epoch": 0.48,
      "grad_norm": 8.665755271911621,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.1757,
      "step": 13800
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.506295204162598,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 3.197,
      "step": 13900
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.310256958007812,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 3.2326,
      "step": 14000
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.287364959716797,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.1491,
      "step": 14100
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.902299880981445,
      "learning_rate": 2.633333333333333e-05,
      "loss": 3.1785,
      "step": 14200
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.109553337097168,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 3.184,
      "step": 14300
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.511371612548828,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.17,
      "step": 14400
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.718900680541992,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 3.203,
      "step": 14500
    },
    {
      "epoch": 0.51,
      "grad_norm": 8.070825576782227,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 3.183,
      "step": 14600
    },
    {
      "epoch": 0.51,
      "grad_norm": 8.945808410644531,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.1448,
      "step": 14700
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.740968704223633,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 3.2433,
      "step": 14800
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.717597007751465,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 3.1931,
      "step": 14900
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.620681762695312,
      "learning_rate": 2.5e-05,
      "loss": 3.2254,
      "step": 15000
    },
    {
      "epoch": 0.52,
      "eval_bleu-4": 0.03633459322725043,
      "eval_rouge-1": 32.393692,
      "eval_rouge-2": 8.12938,
      "eval_rouge-l": 23.165344,
      "eval_runtime": 42.7768,
      "eval_samples_per_second": 1.169,
      "eval_steps_per_second": 0.094,
      "step": 15000
    },
    {
      "epoch": 0.53,
      "grad_norm": 8.360279083251953,
      "learning_rate": 2.4833333333333335e-05,
      "loss": 3.181,
      "step": 15100
    },
    {
      "epoch": 0.53,
      "grad_norm": 11.348652839660645,
      "learning_rate": 2.466666666666667e-05,
      "loss": 3.1439,
      "step": 15200
    },
    {
      "epoch": 0.53,
      "grad_norm": 8.578405380249023,
      "learning_rate": 2.45e-05,
      "loss": 3.1805,
      "step": 15300
    },
    {
      "epoch": 0.54,
      "grad_norm": 8.966902732849121,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 3.1804,
      "step": 15400
    },
    {
      "epoch": 0.54,
      "grad_norm": 8.188057899475098,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 3.2396,
      "step": 15500
    },
    {
      "epoch": 0.54,
      "grad_norm": 10.366168022155762,
      "learning_rate": 2.4e-05,
      "loss": 3.1518,
      "step": 15600
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.700970649719238,
      "learning_rate": 2.3833333333333334e-05,
      "loss": 3.1993,
      "step": 15700
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.457122802734375,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 3.2066,
      "step": 15800
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.52352523803711,
      "learning_rate": 2.35e-05,
      "loss": 3.2109,
      "step": 15900
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.031428337097168,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 3.1683,
      "step": 16000
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.520889282226562,
      "learning_rate": 2.3166666666666666e-05,
      "loss": 3.1484,
      "step": 16100
    },
    {
      "epoch": 0.57,
      "grad_norm": 8.534867286682129,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.0963,
      "step": 16200
    },
    {
      "epoch": 0.57,
      "grad_norm": 8.760907173156738,
      "learning_rate": 2.2833333333333334e-05,
      "loss": 3.1504,
      "step": 16300
    },
    {
      "epoch": 0.57,
      "grad_norm": 8.36541748046875,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 3.1879,
      "step": 16400
    },
    {
      "epoch": 0.58,
      "grad_norm": 8.09740161895752,
      "learning_rate": 2.25e-05,
      "loss": 3.1675,
      "step": 16500
    },
    {
      "epoch": 0.58,
      "eval_bleu-4": 0.03437680651536593,
      "eval_rouge-1": 32.282158,
      "eval_rouge-2": 6.990842,
      "eval_rouge-l": 24.278568,
      "eval_runtime": 32.0426,
      "eval_samples_per_second": 1.56,
      "eval_steps_per_second": 0.125,
      "step": 16500
    },
    {
      "epoch": 0.58,
      "grad_norm": 8.566034317016602,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 3.1466,
      "step": 16600
    },
    {
      "epoch": 0.58,
      "grad_norm": 8.53052043914795,
      "learning_rate": 2.216666666666667e-05,
      "loss": 3.22,
      "step": 16700
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.25809097290039,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.1948,
      "step": 16800
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.109309196472168,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 3.1813,
      "step": 16900
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.857512474060059,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 3.2174,
      "step": 17000
    },
    {
      "epoch": 0.6,
      "grad_norm": 8.707307815551758,
      "learning_rate": 2.15e-05,
      "loss": 3.1939,
      "step": 17100
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.18153190612793,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 3.1564,
      "step": 17200
    },
    {
      "epoch": 0.6,
      "grad_norm": 8.48415756225586,
      "learning_rate": 2.116666666666667e-05,
      "loss": 3.1311,
      "step": 17300
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.630264282226562,
      "learning_rate": 2.1e-05,
      "loss": 3.2001,
      "step": 17400
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.635035514831543,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 3.2184,
      "step": 17500
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.31104564666748,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 3.1538,
      "step": 17600
    },
    {
      "epoch": 0.62,
      "grad_norm": 8.145852088928223,
      "learning_rate": 2.05e-05,
      "loss": 3.1489,
      "step": 17700
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.12879753112793,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 3.1974,
      "step": 17800
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.270123481750488,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 3.2037,
      "step": 17900
    },
    {
      "epoch": 0.63,
      "grad_norm": 8.854657173156738,
      "learning_rate": 2e-05,
      "loss": 3.1552,
      "step": 18000
    },
    {
      "epoch": 0.63,
      "eval_bleu-4": 0.03733361029802693,
      "eval_rouge-1": 32.32956,
      "eval_rouge-2": 7.753536,
      "eval_rouge-l": 25.28641,
      "eval_runtime": 21.6353,
      "eval_samples_per_second": 2.311,
      "eval_steps_per_second": 0.185,
      "step": 18000
    },
    {
      "epoch": 0.63,
      "grad_norm": 8.435654640197754,
      "learning_rate": 1.9833333333333335e-05,
      "loss": 3.2615,
      "step": 18100
    },
    {
      "epoch": 0.64,
      "grad_norm": 8.814099311828613,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 3.2039,
      "step": 18200
    },
    {
      "epoch": 0.64,
      "grad_norm": 9.132009506225586,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.199,
      "step": 18300
    },
    {
      "epoch": 0.64,
      "grad_norm": 10.624908447265625,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 3.1612,
      "step": 18400
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.19758415222168,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 3.1892,
      "step": 18500
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.43676471710205,
      "learning_rate": 1.9e-05,
      "loss": 3.1696,
      "step": 18600
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.103069305419922,
      "learning_rate": 1.8833333333333335e-05,
      "loss": 3.1602,
      "step": 18700
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.961832046508789,
      "learning_rate": 1.866666666666667e-05,
      "loss": 3.1681,
      "step": 18800
    },
    {
      "epoch": 0.66,
      "grad_norm": 8.939531326293945,
      "learning_rate": 1.85e-05,
      "loss": 3.2119,
      "step": 18900
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.692195892333984,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 3.1323,
      "step": 19000
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.751100063323975,
      "learning_rate": 1.8166666666666667e-05,
      "loss": 3.1709,
      "step": 19100
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.450553894042969,
      "learning_rate": 1.8e-05,
      "loss": 3.1497,
      "step": 19200
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.627222061157227,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 3.1721,
      "step": 19300
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.507006645202637,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 3.1339,
      "step": 19400
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.627628326416016,
      "learning_rate": 1.75e-05,
      "loss": 3.1374,
      "step": 19500
    },
    {
      "epoch": 0.68,
      "eval_bleu-4": 0.038305882071799566,
      "eval_rouge-1": 33.15323,
      "eval_rouge-2": 8.108452,
      "eval_rouge-l": 25.739390000000004,
      "eval_runtime": 20.6428,
      "eval_samples_per_second": 2.422,
      "eval_steps_per_second": 0.194,
      "step": 19500
    },
    {
      "epoch": 0.68,
      "grad_norm": 9.371533393859863,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 3.1385,
      "step": 19600
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.198221206665039,
      "learning_rate": 1.7166666666666666e-05,
      "loss": 3.1958,
      "step": 19700
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.20135498046875,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 3.1693,
      "step": 19800
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.644033432006836,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 3.1626,
      "step": 19900
    },
    {
      "epoch": 0.7,
      "grad_norm": 9.05935287475586,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 3.1682,
      "step": 20000
    },
    {
      "epoch": 0.7,
      "grad_norm": 9.094064712524414,
      "learning_rate": 1.65e-05,
      "loss": 3.1812,
      "step": 20100
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.3177490234375,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 3.1441,
      "step": 20200
    },
    {
      "epoch": 0.71,
      "grad_norm": 9.297564506530762,
      "learning_rate": 1.6166666666666665e-05,
      "loss": 3.2301,
      "step": 20300
    },
    {
      "epoch": 0.71,
      "grad_norm": 9.239870071411133,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.1437,
      "step": 20400
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.95326042175293,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 3.1579,
      "step": 20500
    },
    {
      "epoch": 0.72,
      "grad_norm": 9.620644569396973,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 3.1576,
      "step": 20600
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.700374603271484,
      "learning_rate": 1.55e-05,
      "loss": 3.1467,
      "step": 20700
    },
    {
      "epoch": 0.73,
      "grad_norm": 8.052544593811035,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 3.1821,
      "step": 20800
    },
    {
      "epoch": 0.73,
      "grad_norm": 9.161565780639648,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 3.1823,
      "step": 20900
    },
    {
      "epoch": 0.73,
      "grad_norm": 11.46230411529541,
      "learning_rate": 1.5e-05,
      "loss": 3.2196,
      "step": 21000
    },
    {
      "epoch": 0.73,
      "eval_bleu-4": 0.036489724366157564,
      "eval_rouge-1": 33.229724,
      "eval_rouge-2": 8.135995999999999,
      "eval_rouge-l": 25.296698000000003,
      "eval_runtime": 22.4859,
      "eval_samples_per_second": 2.224,
      "eval_steps_per_second": 0.178,
      "step": 21000
    },
    {
      "epoch": 0.74,
      "grad_norm": 8.465361595153809,
      "learning_rate": 1.4833333333333336e-05,
      "loss": 3.1783,
      "step": 21100
    },
    {
      "epoch": 0.74,
      "grad_norm": 9.798529624938965,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 3.1572,
      "step": 21200
    },
    {
      "epoch": 0.74,
      "grad_norm": 9.311988830566406,
      "learning_rate": 1.45e-05,
      "loss": 3.135,
      "step": 21300
    },
    {
      "epoch": 0.75,
      "grad_norm": 10.422714233398438,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 3.1406,
      "step": 21400
    },
    {
      "epoch": 0.75,
      "grad_norm": 10.776314735412598,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 3.1738,
      "step": 21500
    },
    {
      "epoch": 0.75,
      "grad_norm": 8.655586242675781,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.1893,
      "step": 21600
    },
    {
      "epoch": 0.76,
      "grad_norm": 10.017346382141113,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 3.1407,
      "step": 21700
    },
    {
      "epoch": 0.76,
      "grad_norm": 9.955924034118652,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 3.1712,
      "step": 21800
    },
    {
      "epoch": 0.76,
      "grad_norm": 9.687765121459961,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 3.1744,
      "step": 21900
    },
    {
      "epoch": 0.77,
      "grad_norm": 9.429398536682129,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 3.1759,
      "step": 22000
    },
    {
      "epoch": 0.77,
      "grad_norm": 10.031964302062988,
      "learning_rate": 1.3166666666666665e-05,
      "loss": 3.1722,
      "step": 22100
    },
    {
      "epoch": 0.77,
      "grad_norm": 9.295456886291504,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.1574,
      "step": 22200
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.599817276000977,
      "learning_rate": 1.2833333333333333e-05,
      "loss": 3.1815,
      "step": 22300
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.405500411987305,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 3.1519,
      "step": 22400
    },
    {
      "epoch": 0.79,
      "grad_norm": 10.332104682922363,
      "learning_rate": 1.25e-05,
      "loss": 3.187,
      "step": 22500
    },
    {
      "epoch": 0.79,
      "eval_bleu-4": 0.0370179972037972,
      "eval_rouge-1": 33.773592,
      "eval_rouge-2": 7.959636,
      "eval_rouge-l": 25.323794000000003,
      "eval_runtime": 32.3791,
      "eval_samples_per_second": 1.544,
      "eval_steps_per_second": 0.124,
      "step": 22500
    },
    {
      "epoch": 0.79,
      "grad_norm": 10.010290145874023,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 3.1404,
      "step": 22600
    },
    {
      "epoch": 0.79,
      "grad_norm": 9.807190895080566,
      "learning_rate": 1.2166666666666668e-05,
      "loss": 3.1319,
      "step": 22700
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.1905517578125,
      "learning_rate": 1.2e-05,
      "loss": 3.1949,
      "step": 22800
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.210387229919434,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 3.1277,
      "step": 22900
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.007772445678711,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 3.1421,
      "step": 23000
    },
    {
      "epoch": 0.81,
      "grad_norm": 9.395373344421387,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 3.1787,
      "step": 23100
    },
    {
      "epoch": 0.81,
      "grad_norm": 9.005026817321777,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 3.1691,
      "step": 23200
    },
    {
      "epoch": 0.81,
      "grad_norm": 11.29339599609375,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 3.1629,
      "step": 23300
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.865742683410645,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 3.1463,
      "step": 23400
    },
    {
      "epoch": 0.82,
      "grad_norm": 10.309219360351562,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 3.175,
      "step": 23500
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.419913291931152,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 3.1452,
      "step": 23600
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.182723045349121,
      "learning_rate": 1.05e-05,
      "loss": 3.1886,
      "step": 23700
    },
    {
      "epoch": 0.83,
      "grad_norm": 10.771907806396484,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 3.1834,
      "step": 23800
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.413816452026367,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 3.1308,
      "step": 23900
    },
    {
      "epoch": 0.84,
      "grad_norm": 10.597805976867676,
      "learning_rate": 1e-05,
      "loss": 3.1288,
      "step": 24000
    },
    {
      "epoch": 0.84,
      "eval_bleu-4": 0.03709435351803895,
      "eval_rouge-1": 32.914152,
      "eval_rouge-2": 7.755728,
      "eval_rouge-l": 24.262676000000003,
      "eval_runtime": 45.061,
      "eval_samples_per_second": 1.11,
      "eval_steps_per_second": 0.089,
      "step": 24000
    },
    {
      "epoch": 0.84,
      "grad_norm": 10.061678886413574,
      "learning_rate": 9.833333333333333e-06,
      "loss": 3.1239,
      "step": 24100
    },
    {
      "epoch": 0.84,
      "grad_norm": 9.131414413452148,
      "learning_rate": 9.666666666666667e-06,
      "loss": 3.1382,
      "step": 24200
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.998527526855469,
      "learning_rate": 9.5e-06,
      "loss": 3.2199,
      "step": 24300
    },
    {
      "epoch": 0.85,
      "grad_norm": 9.023993492126465,
      "learning_rate": 9.333333333333334e-06,
      "loss": 3.133,
      "step": 24400
    },
    {
      "epoch": 0.86,
      "grad_norm": 9.549063682556152,
      "learning_rate": 9.166666666666666e-06,
      "loss": 3.1591,
      "step": 24500
    },
    {
      "epoch": 0.86,
      "grad_norm": 9.972702026367188,
      "learning_rate": 9e-06,
      "loss": 3.1254,
      "step": 24600
    },
    {
      "epoch": 0.86,
      "grad_norm": 10.49842357635498,
      "learning_rate": 8.833333333333334e-06,
      "loss": 3.144,
      "step": 24700
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.862499237060547,
      "learning_rate": 8.666666666666668e-06,
      "loss": 3.1762,
      "step": 24800
    },
    {
      "epoch": 0.87,
      "grad_norm": 10.071542739868164,
      "learning_rate": 8.500000000000002e-06,
      "loss": 3.161,
      "step": 24900
    },
    {
      "epoch": 0.87,
      "grad_norm": 10.026422500610352,
      "learning_rate": 8.333333333333334e-06,
      "loss": 3.1638,
      "step": 25000
    },
    {
      "epoch": 0.88,
      "grad_norm": 9.016655921936035,
      "learning_rate": 8.166666666666668e-06,
      "loss": 3.1369,
      "step": 25100
    },
    {
      "epoch": 0.88,
      "grad_norm": 10.937761306762695,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.1424,
      "step": 25200
    },
    {
      "epoch": 0.88,
      "grad_norm": 9.711747169494629,
      "learning_rate": 7.833333333333333e-06,
      "loss": 3.1494,
      "step": 25300
    },
    {
      "epoch": 0.89,
      "grad_norm": 9.65941047668457,
      "learning_rate": 7.666666666666667e-06,
      "loss": 3.1738,
      "step": 25400
    },
    {
      "epoch": 0.89,
      "grad_norm": 10.562475204467773,
      "learning_rate": 7.5e-06,
      "loss": 3.1532,
      "step": 25500
    },
    {
      "epoch": 0.89,
      "eval_bleu-4": 0.0372527680789516,
      "eval_rouge-1": 33.53236,
      "eval_rouge-2": 7.783146,
      "eval_rouge-l": 25.788562,
      "eval_runtime": 10.8763,
      "eval_samples_per_second": 4.597,
      "eval_steps_per_second": 0.368,
      "step": 25500
    },
    {
      "epoch": 0.89,
      "grad_norm": 10.032942771911621,
      "learning_rate": 7.333333333333334e-06,
      "loss": 3.1288,
      "step": 25600
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.69816780090332,
      "learning_rate": 7.166666666666667e-06,
      "loss": 3.1604,
      "step": 25700
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.014467239379883,
      "learning_rate": 7.000000000000001e-06,
      "loss": 3.1471,
      "step": 25800
    },
    {
      "epoch": 0.9,
      "grad_norm": 10.939640045166016,
      "learning_rate": 6.833333333333333e-06,
      "loss": 3.1837,
      "step": 25900
    },
    {
      "epoch": 0.91,
      "grad_norm": 9.37083911895752,
      "learning_rate": 6.666666666666667e-06,
      "loss": 3.1453,
      "step": 26000
    },
    {
      "epoch": 0.91,
      "grad_norm": 9.23774242401123,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 3.1325,
      "step": 26100
    },
    {
      "epoch": 0.91,
      "grad_norm": 8.956214904785156,
      "learning_rate": 6.333333333333334e-06,
      "loss": 3.1932,
      "step": 26200
    },
    {
      "epoch": 0.92,
      "grad_norm": 10.790550231933594,
      "learning_rate": 6.166666666666667e-06,
      "loss": 3.1584,
      "step": 26300
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.379403114318848,
      "learning_rate": 6e-06,
      "loss": 3.1665,
      "step": 26400
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.832858085632324,
      "learning_rate": 5.833333333333334e-06,
      "loss": 3.2006,
      "step": 26500
    },
    {
      "epoch": 0.93,
      "grad_norm": 11.349075317382812,
      "learning_rate": 5.666666666666667e-06,
      "loss": 3.1466,
      "step": 26600
    },
    {
      "epoch": 0.93,
      "grad_norm": 9.609334945678711,
      "learning_rate": 5.500000000000001e-06,
      "loss": 3.1535,
      "step": 26700
    },
    {
      "epoch": 0.94,
      "grad_norm": 9.871110916137695,
      "learning_rate": 5.333333333333334e-06,
      "loss": 3.1392,
      "step": 26800
    },
    {
      "epoch": 0.94,
      "grad_norm": 11.199357986450195,
      "learning_rate": 5.166666666666667e-06,
      "loss": 3.122,
      "step": 26900
    },
    {
      "epoch": 0.94,
      "grad_norm": 9.498676300048828,
      "learning_rate": 5e-06,
      "loss": 3.1616,
      "step": 27000
    },
    {
      "epoch": 0.94,
      "eval_bleu-4": 0.03837696447954937,
      "eval_rouge-1": 33.189338,
      "eval_rouge-2": 8.122198000000001,
      "eval_rouge-l": 25.914390000000004,
      "eval_runtime": 22.5274,
      "eval_samples_per_second": 2.22,
      "eval_steps_per_second": 0.178,
      "step": 27000
    },
    {
      "epoch": 0.95,
      "grad_norm": 9.666454315185547,
      "learning_rate": 4.833333333333333e-06,
      "loss": 3.1342,
      "step": 27100
    },
    {
      "epoch": 0.95,
      "grad_norm": 10.01155948638916,
      "learning_rate": 4.666666666666667e-06,
      "loss": 3.1407,
      "step": 27200
    },
    {
      "epoch": 0.95,
      "grad_norm": 10.286541938781738,
      "learning_rate": 4.5e-06,
      "loss": 3.1321,
      "step": 27300
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.009024620056152,
      "learning_rate": 4.333333333333334e-06,
      "loss": 3.131,
      "step": 27400
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.619215965270996,
      "learning_rate": 4.166666666666667e-06,
      "loss": 3.153,
      "step": 27500
    },
    {
      "epoch": 0.96,
      "grad_norm": 12.227978706359863,
      "learning_rate": 4.000000000000001e-06,
      "loss": 3.1515,
      "step": 27600
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.663722038269043,
      "learning_rate": 3.833333333333334e-06,
      "loss": 3.1134,
      "step": 27700
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.554591178894043,
      "learning_rate": 3.666666666666667e-06,
      "loss": 3.1555,
      "step": 27800
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.34001636505127,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 3.1204,
      "step": 27900
    },
    {
      "epoch": 0.98,
      "grad_norm": 9.24498176574707,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 3.1176,
      "step": 28000
    },
    {
      "epoch": 0.98,
      "grad_norm": 9.317843437194824,
      "learning_rate": 3.166666666666667e-06,
      "loss": 3.1014,
      "step": 28100
    },
    {
      "epoch": 0.98,
      "grad_norm": 10.217525482177734,
      "learning_rate": 3e-06,
      "loss": 3.1601,
      "step": 28200
    },
    {
      "epoch": 0.99,
      "grad_norm": 11.810629844665527,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 3.1537,
      "step": 28300
    },
    {
      "epoch": 0.99,
      "grad_norm": 9.95785140991211,
      "learning_rate": 2.666666666666667e-06,
      "loss": 3.1187,
      "step": 28400
    },
    {
      "epoch": 0.99,
      "grad_norm": 10.151300430297852,
      "learning_rate": 2.5e-06,
      "loss": 3.1615,
      "step": 28500
    },
    {
      "epoch": 0.99,
      "eval_bleu-4": 0.03675185008347854,
      "eval_rouge-1": 32.996221999999996,
      "eval_rouge-2": 7.63717,
      "eval_rouge-l": 25.360564000000004,
      "eval_runtime": 23.0466,
      "eval_samples_per_second": 2.17,
      "eval_steps_per_second": 0.174,
      "step": 28500
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.851890563964844,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 3.1435,
      "step": 28600
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.042054176330566,
      "learning_rate": 2.166666666666667e-06,
      "loss": 3.1134,
      "step": 28700
    },
    {
      "epoch": 1.01,
      "grad_norm": 9.963356018066406,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.1322,
      "step": 28800
    },
    {
      "epoch": 1.01,
      "grad_norm": 9.53222942352295,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 3.1115,
      "step": 28900
    },
    {
      "epoch": 1.01,
      "grad_norm": 10.219050407409668,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 3.0793,
      "step": 29000
    },
    {
      "epoch": 1.02,
      "grad_norm": 10.052590370178223,
      "learning_rate": 1.5e-06,
      "loss": 3.123,
      "step": 29100
    },
    {
      "epoch": 1.02,
      "grad_norm": 9.902127265930176,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 3.0997,
      "step": 29200
    },
    {
      "epoch": 1.02,
      "grad_norm": 11.275967597961426,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 3.084,
      "step": 29300
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.979484558105469,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 3.1069,
      "step": 29400
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.366888999938965,
      "learning_rate": 8.333333333333333e-07,
      "loss": 3.1119,
      "step": 29500
    },
    {
      "epoch": 1.03,
      "grad_norm": 8.998619079589844,
      "learning_rate": 6.666666666666667e-07,
      "loss": 3.1558,
      "step": 29600
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.672365188598633,
      "learning_rate": 5.000000000000001e-07,
      "loss": 3.0649,
      "step": 29700
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.450902938842773,
      "learning_rate": 3.3333333333333335e-07,
      "loss": 3.1411,
      "step": 29800
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.263570785522461,
      "learning_rate": 1.6666666666666668e-07,
      "loss": 3.1286,
      "step": 29900
    },
    {
      "epoch": 1.05,
      "grad_norm": 10.28285026550293,
      "learning_rate": 0.0,
      "loss": 3.0957,
      "step": 30000
    },
    {
      "epoch": 1.05,
      "eval_bleu-4": 0.037390401350964365,
      "eval_rouge-1": 32.882992,
      "eval_rouge-2": 7.872908000000001,
      "eval_rouge-l": 25.06591,
      "eval_runtime": 32.5338,
      "eval_samples_per_second": 1.537,
      "eval_steps_per_second": 0.123,
      "step": 30000
    }
  ],
  "logging_steps": 100,
  "max_steps": 30000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 3000,
  "total_flos": 6.501955608035205e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
