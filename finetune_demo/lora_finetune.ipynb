{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {},
   "source": [
    "# Homework 使用官方提供的示例，成功微调出广告数据集，要求使用 Lora 进行微调：\n",
    "\n",
    "1. 你能看到 loss 的下降，并在最终回到 3.2 左右。\n",
    "## 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB\n",
    "显卡架构：安培架构（推荐）\n",
    "内存：16GB# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB\n",
    "显卡架构：安培架构（推荐）\n",
    "内存：16GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {},
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen\n",
    "\n",
    "接着，运行本代码来切割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T05:02:34.749308Z",
     "start_time": "2024-01-18T05:02:25.564458Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {},
   "source": [
    "## 2. 使用命令行进行 LoRA 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01573ebb-0595-4a7b-b49e-ed572d338c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ff482-b103-41dd-898b-e7aa50fe2607",
   "metadata": {},
   "source": [
    "### 注意安装各种依赖，很多，一个个安吧，，，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T06:44:56.043246Z",
     "start_time": "2024-01-18T05:05:28.425374Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
      "- tokenization_chatglm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:03<00:00,  1.92it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 114599 examples [00:00, 368511.96 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
      "Generating validation split: 1070 examples [00:00, 78822.30 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
      "Generating test split: 1070 examples [00:00, 76654.74 examples/s]\n",
      "Map (num_proc=16): 100%|██████| 114599/114599 [00:02<00:00, 40737.63 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 1094.67 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|████████████| 1070/1070 [00:01<00:00, 893.43 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "{'loss': 4.0998, 'grad_norm': 3.3816967010498047, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6566, 'grad_norm': 4.492903232574463, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5709, 'grad_norm': 5.866041660308838, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4934, 'grad_norm': 5.59262228012085, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.504, 'grad_norm': 5.921512126922607, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4856, 'grad_norm': 6.46125602722168, 'learning_rate': 4.9e-05, 'epoch': 0.02}\n",
      "{'loss': 3.437, 'grad_norm': 6.311365604400635, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4666, 'grad_norm': 6.843714714050293, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4033, 'grad_norm': 7.58450984954834, 'learning_rate': 4.85e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4396, 'grad_norm': 7.917341232299805, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4519, 'grad_norm': 6.450716972351074, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4021, 'grad_norm': 6.200622081756592, 'learning_rate': 4.8e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3704, 'grad_norm': 7.147000312805176, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3923, 'grad_norm': 6.344797134399414, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.362, 'grad_norm': 6.620858192443848, 'learning_rate': 4.75e-05, 'epoch': 0.05}\n",
      "  5%|█▊                                  | 1500/30000 [05:29<1:33:12,  5.10it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.15s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.73s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.534 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 32.466927999999996, 'eval_rouge-2': 6.2366259999999984, 'eval_rouge-l': 25.638175999999998, 'eval_bleu-4': 0.031654737549697456, 'eval_runtime': 11.769, 'eval_samples_per_second': 4.248, 'eval_steps_per_second': 0.34, 'epoch': 0.05}\n",
      "  5%|█▊                                  | 1500/30000 [05:40<1:33:12,  5.10it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:07<00:00,  1.73s/it]\u001b[A\n",
      "{'loss': 3.4236, 'grad_norm': 6.857300758361816, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3894, 'grad_norm': 6.49027156829834, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4092, 'grad_norm': 7.2672343254089355, 'learning_rate': 4.7e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3883, 'grad_norm': 7.175048828125, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3732, 'grad_norm': 7.660699844360352, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.423, 'grad_norm': 7.239548683166504, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3937, 'grad_norm': 6.4523725509643555, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3742, 'grad_norm': 7.234979629516602, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3492, 'grad_norm': 6.558632850646973, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3578, 'grad_norm': 8.407913208007812, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3791, 'grad_norm': 7.687345027923584, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4003, 'grad_norm': 8.331189155578613, 'learning_rate': 4.55e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3305, 'grad_norm': 7.081035614013672, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3775, 'grad_norm': 8.01138687133789, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3321, 'grad_norm': 6.9842681884765625, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n",
      " 10%|███▌                                | 3000/30000 [11:07<1:31:13,  4.93it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.36s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.46s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.497158000000006, 'eval_rouge-2': 6.728413999999999, 'eval_rouge-l': 24.417794, 'eval_bleu-4': 0.03292464521129044, 'eval_runtime': 31.3243, 'eval_samples_per_second': 1.596, 'eval_steps_per_second': 0.128, 'epoch': 0.1}\n",
      " 10%|███▌                                | 3000/30000 [11:38<1:31:13,  4.93it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  3.80s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-3000/special_tokens_map.json\n",
      "{'loss': 3.3422, 'grad_norm': 6.848629474639893, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3638, 'grad_norm': 7.374202728271484, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3565, 'grad_norm': 6.524794578552246, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3335, 'grad_norm': 6.606592655181885, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3081, 'grad_norm': 7.047088146209717, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.12}\n",
      "{'loss': 3.292, 'grad_norm': 7.416216850280762, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3277, 'grad_norm': 7.915158271789551, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2913, 'grad_norm': 7.260871887207031, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.13}\n",
      "{'loss': 3.355, 'grad_norm': 7.2741007804870605, 'learning_rate': 4.35e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3625, 'grad_norm': 8.116850852966309, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3179, 'grad_norm': 7.622319221496582, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3329, 'grad_norm': 7.524164199829102, 'learning_rate': 4.3e-05, 'epoch': 0.15}\n",
      "{'loss': 3.3137, 'grad_norm': 7.347012519836426, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.15}\n",
      "{'loss': 3.282, 'grad_norm': 7.168367385864258, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.15}\n",
      "{'loss': 3.3071, 'grad_norm': 7.58353328704834, 'learning_rate': 4.25e-05, 'epoch': 0.16}\n",
      " 15%|█████▍                              | 4500/30000 [17:03<1:38:02,  4.33it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.44s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.55s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.267053999999995, 'eval_rouge-2': 6.605848000000001, 'eval_rouge-l': 24.909687999999996, 'eval_bleu-4': 0.03369212717342125, 'eval_runtime': 30.8633, 'eval_samples_per_second': 1.62, 'eval_steps_per_second': 0.13, 'epoch': 0.16}\n",
      " 15%|█████▍                              | 4500/30000 [17:34<1:38:02,  4.33it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:27<00:00,  7.47s/it]\u001b[A\n",
      "{'loss': 3.2983, 'grad_norm': 8.520147323608398, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.16}\n",
      "{'loss': 3.3613, 'grad_norm': 7.837972164154053, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.16}\n",
      "{'loss': 3.3368, 'grad_norm': 7.7235612869262695, 'learning_rate': 4.2e-05, 'epoch': 0.17}\n",
      "{'loss': 3.2952, 'grad_norm': 8.104629516601562, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.17}\n",
      "{'loss': 3.2682, 'grad_norm': 7.068364143371582, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.17}\n",
      "{'loss': 3.324, 'grad_norm': 7.032731056213379, 'learning_rate': 4.15e-05, 'epoch': 0.18}\n",
      "{'loss': 3.2914, 'grad_norm': 6.817259311676025, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.18}\n",
      "{'loss': 3.2458, 'grad_norm': 7.231662273406982, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.18}\n",
      "{'loss': 3.2559, 'grad_norm': 7.310662269592285, 'learning_rate': 4.1e-05, 'epoch': 0.19}\n",
      "{'loss': 3.2891, 'grad_norm': 7.8040900230407715, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.19}\n",
      "{'loss': 3.2977, 'grad_norm': 7.116990089416504, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.2}\n",
      "{'loss': 3.313, 'grad_norm': 8.878244400024414, 'learning_rate': 4.05e-05, 'epoch': 0.2}\n",
      "{'loss': 3.3236, 'grad_norm': 6.9786224365234375, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.2}\n",
      "{'loss': 3.2121, 'grad_norm': 7.404692649841309, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.21}\n",
      "{'loss': 3.3709, 'grad_norm': 7.567892074584961, 'learning_rate': 4e-05, 'epoch': 0.21}\n",
      " 20%|███████▏                            | 6000/30000 [22:59<1:27:29,  4.57it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.46s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.58s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.546764, 'eval_rouge-2': 6.372103999999999, 'eval_rouge-l': 23.207274, 'eval_bleu-4': 0.029107160791152983, 'eval_runtime': 30.9565, 'eval_samples_per_second': 1.615, 'eval_steps_per_second': 0.129, 'epoch': 0.21}\n",
      " 20%|███████▏                            | 6000/30000 [23:30<1:27:29,  4.57it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  3.44s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-6000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-6000/special_tokens_map.json\n",
      "{'loss': 3.2622, 'grad_norm': 8.381339073181152, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.21}\n",
      "{'loss': 3.2722, 'grad_norm': 7.896162033081055, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.22}\n",
      "{'loss': 3.2732, 'grad_norm': 7.553103446960449, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.22}\n",
      "{'loss': 3.3505, 'grad_norm': 7.0459885597229, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.22}\n",
      "{'loss': 3.3092, 'grad_norm': 7.475334644317627, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.23}\n",
      "{'loss': 3.2961, 'grad_norm': 7.8273606300354, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.23}\n",
      "{'loss': 3.239, 'grad_norm': 6.998303413391113, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.23}\n",
      "{'loss': 3.2813, 'grad_norm': 7.689953327178955, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.24}\n",
      "{'loss': 3.2846, 'grad_norm': 8.031445503234863, 'learning_rate': 3.85e-05, 'epoch': 0.24}\n",
      "{'loss': 3.2727, 'grad_norm': 6.974882125854492, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.24}\n",
      "{'loss': 3.2796, 'grad_norm': 7.11702299118042, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.25}\n",
      "{'loss': 3.2884, 'grad_norm': 6.94666862487793, 'learning_rate': 3.8e-05, 'epoch': 0.25}\n",
      "{'loss': 3.2466, 'grad_norm': 7.906581401824951, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.25}\n",
      "{'loss': 3.2519, 'grad_norm': 8.117607116699219, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.26}\n",
      "{'loss': 3.227, 'grad_norm': 7.816051006317139, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.26}\n",
      " 25%|█████████                           | 7500/30000 [28:57<1:13:08,  5.13it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.37s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.41s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.35561200000001, 'eval_rouge-2': 7.364516, 'eval_rouge-l': 24.364030000000003, 'eval_bleu-4': 0.033163205779497586, 'eval_runtime': 40.4179, 'eval_samples_per_second': 1.237, 'eval_steps_per_second': 0.099, 'epoch': 0.26}\n",
      " 25%|█████████                           | 7500/30000 [29:37<1:13:08,  5.13it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:26<00:00,  7.11s/it]\u001b[A\n",
      "{'loss': 3.3064, 'grad_norm': 7.516470432281494, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.27}\n",
      "{'loss': 3.2524, 'grad_norm': 7.807693958282471, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.27}\n",
      "{'loss': 3.2662, 'grad_norm': 7.136553764343262, 'learning_rate': 3.7e-05, 'epoch': 0.27}\n",
      "{'loss': 3.2655, 'grad_norm': 8.226905822753906, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2609, 'grad_norm': 8.049156188964844, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2265, 'grad_norm': 8.370140075683594, 'learning_rate': 3.65e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2796, 'grad_norm': 8.002985954284668, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2594, 'grad_norm': 7.058302402496338, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2422, 'grad_norm': 8.745269775390625, 'learning_rate': 3.6e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2365, 'grad_norm': 7.3970818519592285, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.3}\n",
      "{'loss': 3.2467, 'grad_norm': 8.398171424865723, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.3}\n",
      "{'loss': 3.2778, 'grad_norm': 7.730616569519043, 'learning_rate': 3.55e-05, 'epoch': 0.3}\n",
      "{'loss': 3.2468, 'grad_norm': 7.915294170379639, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2546, 'grad_norm': 7.6402268409729, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2728, 'grad_norm': 8.473834991455078, 'learning_rate': 3.5e-05, 'epoch': 0.31}\n",
      " 30%|██████████▊                         | 9000/30000 [35:04<1:16:44,  4.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.28s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.403518, 'eval_rouge-2': 7.424269999999999, 'eval_rouge-l': 25.030917999999996, 'eval_bleu-4': 0.03752731284791531, 'eval_runtime': 10.8787, 'eval_samples_per_second': 4.596, 'eval_steps_per_second': 0.368, 'epoch': 0.31}\n",
      " 30%|██████████▊                         | 9000/30000 [35:15<1:16:44,  4.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:07<00:00,  1.94s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-9000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-9000/special_tokens_map.json\n",
      "{'loss': 3.2389, 'grad_norm': 8.539925575256348, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2087, 'grad_norm': 8.227707862854004, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2438, 'grad_norm': 7.553668975830078, 'learning_rate': 3.45e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2425, 'grad_norm': 9.049419403076172, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.33}\n",
      "{'loss': 3.1839, 'grad_norm': 8.088829040527344, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.33}\n",
      "{'loss': 3.2564, 'grad_norm': 7.471137523651123, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.34}\n",
      "{'loss': 3.2581, 'grad_norm': 8.96998405456543, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.34}\n",
      "{'loss': 3.2819, 'grad_norm': 8.347500801086426, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.34}\n",
      "{'loss': 3.1836, 'grad_norm': 9.397418975830078, 'learning_rate': 3.35e-05, 'epoch': 0.35}\n",
      "{'loss': 3.2347, 'grad_norm': 7.614259719848633, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.35}\n",
      "{'loss': 3.2289, 'grad_norm': 7.910367488861084, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.35}\n",
      "{'loss': 3.2411, 'grad_norm': 7.66641902923584, 'learning_rate': 3.3e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2495, 'grad_norm': 8.076035499572754, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2357, 'grad_norm': 10.04578971862793, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2332, 'grad_norm': 7.594321250915527, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.37}\n",
      " 35%|████████████▎                      | 10500/30000 [40:41<1:10:06,  4.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.39s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:25<00:08,  8.97s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.116278, 'eval_rouge-2': 7.358334, 'eval_rouge-l': 23.518251999999997, 'eval_bleu-4': 0.033763136077845556, 'eval_runtime': 42.2872, 'eval_samples_per_second': 1.182, 'eval_steps_per_second': 0.095, 'epoch': 0.37}\n",
      " 35%|████████████▎                      | 10500/30000 [41:24<1:10:06,  4.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:27<00:00,  6.41s/it]\u001b[A\n",
      "{'loss': 3.2092, 'grad_norm': 7.974515914916992, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.37}\n",
      "{'loss': 3.2158, 'grad_norm': 8.548613548278809, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.37}\n",
      "{'loss': 3.2284, 'grad_norm': 7.679333686828613, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2306, 'grad_norm': 8.283294677734375, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.38}\n",
      "{'loss': 3.1839, 'grad_norm': 8.043553352355957, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2323, 'grad_norm': 8.346972465515137, 'learning_rate': 3.15e-05, 'epoch': 0.39}\n",
      "{'loss': 3.1967, 'grad_norm': 8.319920539855957, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.39}\n",
      "{'loss': 3.2282, 'grad_norm': 9.384533882141113, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.39}\n",
      "{'loss': 3.2192, 'grad_norm': 8.684137344360352, 'learning_rate': 3.1e-05, 'epoch': 0.4}\n",
      "{'loss': 3.1987, 'grad_norm': 7.533777236938477, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2789, 'grad_norm': 7.364867687225342, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.4}\n",
      "{'loss': 3.1868, 'grad_norm': 9.660798072814941, 'learning_rate': 3.05e-05, 'epoch': 0.41}\n",
      "{'loss': 3.2291, 'grad_norm': 7.859309196472168, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.41}\n",
      "{'loss': 3.1902, 'grad_norm': 8.283267974853516, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.42}\n",
      "{'loss': 3.1888, 'grad_norm': 8.768928527832031, 'learning_rate': 3e-05, 'epoch': 0.42}\n",
      " 40%|██████████████                     | 12000/30000 [46:48<1:05:33,  4.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.39s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:25<00:08,  8.97s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.512648, 'eval_rouge-2': 8.017550000000002, 'eval_rouge-l': 24.02753, 'eval_bleu-4': 0.03415489902775122, 'eval_runtime': 41.5739, 'eval_samples_per_second': 1.203, 'eval_steps_per_second': 0.096, 'epoch': 0.42}\n",
      " 40%|██████████████                     | 12000/30000 [47:30<1:05:33,  4.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:27<00:00,  6.23s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-12000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-12000/special_tokens_map.json\n",
      "{'loss': 3.1905, 'grad_norm': 8.963590621948242, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.42}\n",
      "{'loss': 3.1718, 'grad_norm': 7.704070568084717, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2019, 'grad_norm': 9.15146255493164, 'learning_rate': 2.95e-05, 'epoch': 0.43}\n",
      "{'loss': 3.1967, 'grad_norm': 8.576027870178223, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2266, 'grad_norm': 8.116244316101074, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.44}\n",
      "{'loss': 3.2035, 'grad_norm': 8.342940330505371, 'learning_rate': 2.9e-05, 'epoch': 0.44}\n",
      "{'loss': 3.1924, 'grad_norm': 8.910335540771484, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.44}\n",
      "{'loss': 3.1899, 'grad_norm': 8.136967658996582, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.45}\n",
      "{'loss': 3.1844, 'grad_norm': 8.597445487976074, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.45}\n",
      "{'loss': 3.1722, 'grad_norm': 9.372090339660645, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.45}\n",
      "{'loss': 3.1867, 'grad_norm': 8.78925609588623, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.46}\n",
      "{'loss': 3.2138, 'grad_norm': 7.877357482910156, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.46}\n",
      "{'loss': 3.1759, 'grad_norm': 8.283772468566895, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.46}\n",
      "{'loss': 3.2233, 'grad_norm': 8.673929214477539, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2051, 'grad_norm': 8.636197090148926, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.47}\n",
      " 45%|████████████████▋                    | 13500/30000 [52:59<59:32,  4.62it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.40s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:25<00:08,  8.99s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.901638000000002, 'eval_rouge-2': 7.6265920000000005, 'eval_rouge-l': 23.616390000000003, 'eval_bleu-4': 0.03415873760849692, 'eval_runtime': 42.4581, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 0.094, 'epoch': 0.47}\n",
      " 45%|████████████████▋                    | 13500/30000 [53:42<59:32,  4.62it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:37<00:00,  9.99s/it]\u001b[A\n",
      "{'loss': 3.2091, 'grad_norm': 8.352869033813477, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2016, 'grad_norm': 9.096405029296875, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.48}\n",
      "{'loss': 3.1757, 'grad_norm': 8.665755271911621, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 3.197, 'grad_norm': 8.506295204162598, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.49}\n",
      "{'loss': 3.2326, 'grad_norm': 8.310256958007812, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.49}\n",
      "{'loss': 3.1491, 'grad_norm': 8.287364959716797, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.49}\n",
      "{'loss': 3.1785, 'grad_norm': 8.902299880981445, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.5}\n",
      "{'loss': 3.184, 'grad_norm': 8.109553337097168, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.5}\n",
      "{'loss': 3.17, 'grad_norm': 8.511371612548828, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.5}\n",
      "{'loss': 3.203, 'grad_norm': 7.718900680541992, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.51}\n",
      "{'loss': 3.183, 'grad_norm': 8.070825576782227, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.51}\n",
      "{'loss': 3.1448, 'grad_norm': 8.945808410644531, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.51}\n",
      "{'loss': 3.2433, 'grad_norm': 8.740968704223633, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.52}\n",
      "{'loss': 3.1931, 'grad_norm': 8.717597007751465, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.52}\n",
      "{'loss': 3.2254, 'grad_norm': 8.620681762695312, 'learning_rate': 2.5e-05, 'epoch': 0.52}\n",
      " 50%|██████████████████▌                  | 15000/30000 [59:07<53:45,  4.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.45s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:25<00:09,  9.05s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.393692, 'eval_rouge-2': 8.12938, 'eval_rouge-l': 23.165344, 'eval_bleu-4': 0.03633459322725043, 'eval_runtime': 42.7768, 'eval_samples_per_second': 1.169, 'eval_steps_per_second': 0.094, 'epoch': 0.52}\n",
      " 50%|██████████████████▌                  | 15000/30000 [59:50<53:45,  4.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:27<00:00,  6.37s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-15000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-15000/special_tokens_map.json\n",
      "{'loss': 3.181, 'grad_norm': 8.360279083251953, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.53}\n",
      "{'loss': 3.1439, 'grad_norm': 11.348652839660645, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.53}\n",
      "{'loss': 3.1805, 'grad_norm': 8.578405380249023, 'learning_rate': 2.45e-05, 'epoch': 0.53}\n",
      "{'loss': 3.1804, 'grad_norm': 8.966902732849121, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.54}\n",
      "{'loss': 3.2396, 'grad_norm': 8.188057899475098, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.54}\n",
      "{'loss': 3.1518, 'grad_norm': 10.366168022155762, 'learning_rate': 2.4e-05, 'epoch': 0.54}\n",
      "{'loss': 3.1993, 'grad_norm': 8.700970649719238, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.55}\n",
      "{'loss': 3.2066, 'grad_norm': 8.457122802734375, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.55}\n",
      "{'loss': 3.2109, 'grad_norm': 8.52352523803711, 'learning_rate': 2.35e-05, 'epoch': 0.55}\n",
      "{'loss': 3.1683, 'grad_norm': 8.031428337097168, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1484, 'grad_norm': 8.520889282226562, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.56}\n",
      "{'loss': 3.0963, 'grad_norm': 8.534867286682129, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.57}\n",
      "{'loss': 3.1504, 'grad_norm': 8.760907173156738, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.57}\n",
      "{'loss': 3.1879, 'grad_norm': 8.36541748046875, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.57}\n",
      "{'loss': 3.1675, 'grad_norm': 8.09740161895752, 'learning_rate': 2.25e-05, 'epoch': 0.58}\n",
      " 55%|███████████████████▎               | 16500/30000 [1:05:21<49:41,  4.53it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.16s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:15<00:05,  5.97s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.282158, 'eval_rouge-2': 6.990842, 'eval_rouge-l': 24.278568, 'eval_bleu-4': 0.03437680651536593, 'eval_runtime': 32.0426, 'eval_samples_per_second': 1.56, 'eval_steps_per_second': 0.125, 'epoch': 0.58}\n",
      " 55%|███████████████████▎               | 16500/30000 [1:05:53<49:41,  4.53it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  4.47s/it]\u001b[A\n",
      "{'loss': 3.1466, 'grad_norm': 8.566034317016602, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.58}\n",
      "{'loss': 3.22, 'grad_norm': 8.53052043914795, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 3.1948, 'grad_norm': 9.25809097290039, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.59}\n",
      "{'loss': 3.1813, 'grad_norm': 9.109309196472168, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.59}\n",
      "{'loss': 3.2174, 'grad_norm': 8.857512474060059, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.59}\n",
      "{'loss': 3.1939, 'grad_norm': 8.707307815551758, 'learning_rate': 2.15e-05, 'epoch': 0.6}\n",
      "{'loss': 3.1564, 'grad_norm': 9.18153190612793, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.6}\n",
      "{'loss': 3.1311, 'grad_norm': 8.48415756225586, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2001, 'grad_norm': 8.630264282226562, 'learning_rate': 2.1e-05, 'epoch': 0.61}\n",
      "{'loss': 3.2184, 'grad_norm': 8.635035514831543, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.61}\n",
      "{'loss': 3.1538, 'grad_norm': 8.31104564666748, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.61}\n",
      "{'loss': 3.1489, 'grad_norm': 8.145852088928223, 'learning_rate': 2.05e-05, 'epoch': 0.62}\n",
      "{'loss': 3.1974, 'grad_norm': 9.12879753112793, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.62}\n",
      "{'loss': 3.2037, 'grad_norm': 9.270123481750488, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.62}\n",
      "{'loss': 3.1552, 'grad_norm': 8.854657173156738, 'learning_rate': 2e-05, 'epoch': 0.63}\n",
      " 60%|█████████████████████              | 18000/30000 [1:11:19<43:32,  4.59it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.37s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.32956, 'eval_rouge-2': 7.753536, 'eval_rouge-l': 25.28641, 'eval_bleu-4': 0.03733361029802693, 'eval_runtime': 21.6353, 'eval_samples_per_second': 2.311, 'eval_steps_per_second': 0.185, 'epoch': 0.63}\n",
      " 60%|█████████████████████              | 18000/30000 [1:11:41<43:32,  4.59it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-18000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-18000/special_tokens_map.json\n",
      "{'loss': 3.2615, 'grad_norm': 8.435654640197754, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.63}\n",
      "{'loss': 3.2039, 'grad_norm': 8.814099311828613, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.64}\n",
      "{'loss': 3.199, 'grad_norm': 9.132009506225586, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 3.1612, 'grad_norm': 10.624908447265625, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.64}\n",
      "{'loss': 3.1892, 'grad_norm': 9.19758415222168, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 3.1696, 'grad_norm': 9.43676471710205, 'learning_rate': 1.9e-05, 'epoch': 0.65}\n",
      "{'loss': 3.1602, 'grad_norm': 9.103069305419922, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.65}\n",
      "{'loss': 3.1681, 'grad_norm': 9.961832046508789, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.66}\n",
      "{'loss': 3.2119, 'grad_norm': 8.939531326293945, 'learning_rate': 1.85e-05, 'epoch': 0.66}\n",
      "{'loss': 3.1323, 'grad_norm': 9.692195892333984, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.66}\n",
      "{'loss': 3.1709, 'grad_norm': 7.751100063323975, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.67}\n",
      "{'loss': 3.1497, 'grad_norm': 9.450553894042969, 'learning_rate': 1.8e-05, 'epoch': 0.67}\n",
      "{'loss': 3.1721, 'grad_norm': 9.627222061157227, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.67}\n",
      "{'loss': 3.1339, 'grad_norm': 8.507006645202637, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.68}\n",
      "{'loss': 3.1374, 'grad_norm': 8.627628326416016, 'learning_rate': 1.75e-05, 'epoch': 0.68}\n",
      " 65%|██████████████████████▊            | 19500/30000 [1:17:06<40:10,  4.36it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.42s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.48s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 33.15323, 'eval_rouge-2': 8.108452, 'eval_rouge-l': 25.739390000000004, 'eval_bleu-4': 0.038305882071799566, 'eval_runtime': 20.6428, 'eval_samples_per_second': 2.422, 'eval_steps_per_second': 0.194, 'epoch': 0.68}\n",
      " 65%|██████████████████████▊            | 19500/30000 [1:17:27<40:10,  4.36it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  3.67s/it]\u001b[A\n",
      "{'loss': 3.1385, 'grad_norm': 9.371533393859863, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.68}\n",
      "{'loss': 3.1958, 'grad_norm': 9.198221206665039, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.69}\n",
      "{'loss': 3.1693, 'grad_norm': 8.20135498046875, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.69}\n",
      "{'loss': 3.1626, 'grad_norm': 8.644033432006836, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.69}\n",
      "{'loss': 3.1682, 'grad_norm': 9.05935287475586, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.7}\n",
      "{'loss': 3.1812, 'grad_norm': 9.094064712524414, 'learning_rate': 1.65e-05, 'epoch': 0.7}\n",
      "{'loss': 3.1441, 'grad_norm': 8.3177490234375, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.71}\n",
      "{'loss': 3.2301, 'grad_norm': 9.297564506530762, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.71}\n",
      "{'loss': 3.1437, 'grad_norm': 9.239870071411133, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.71}\n",
      "{'loss': 3.1579, 'grad_norm': 8.95326042175293, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1576, 'grad_norm': 9.620644569396973, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1467, 'grad_norm': 8.700374603271484, 'learning_rate': 1.55e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1821, 'grad_norm': 8.052544593811035, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.73}\n",
      "{'loss': 3.1823, 'grad_norm': 9.161565780639648, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.73}\n",
      "{'loss': 3.2196, 'grad_norm': 11.46230411529541, 'learning_rate': 1.5e-05, 'epoch': 0.73}\n",
      " 70%|████████████████████████▌          | 21000/30000 [1:22:52<28:55,  5.19it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.14s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.96s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 33.229724, 'eval_rouge-2': 8.135995999999999, 'eval_rouge-l': 25.296698000000003, 'eval_bleu-4': 0.036489724366157564, 'eval_runtime': 22.4859, 'eval_samples_per_second': 2.224, 'eval_steps_per_second': 0.178, 'epoch': 0.73}\n",
      " 70%|████████████████████████▌          | 21000/30000 [1:23:15<28:55,  5.19it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:08<00:00,  2.04s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-21000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-21000/special_tokens_map.json\n",
      "{'loss': 3.1783, 'grad_norm': 8.465361595153809, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.74}\n",
      "{'loss': 3.1572, 'grad_norm': 9.798529624938965, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.74}\n",
      "{'loss': 3.135, 'grad_norm': 9.311988830566406, 'learning_rate': 1.45e-05, 'epoch': 0.74}\n",
      "{'loss': 3.1406, 'grad_norm': 10.422714233398438, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1738, 'grad_norm': 10.776314735412598, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1893, 'grad_norm': 8.655586242675781, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1407, 'grad_norm': 10.017346382141113, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.76}\n",
      "{'loss': 3.1712, 'grad_norm': 9.955924034118652, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.76}\n",
      "{'loss': 3.1744, 'grad_norm': 9.687765121459961, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.76}\n",
      "{'loss': 3.1759, 'grad_norm': 9.429398536682129, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.77}\n",
      "{'loss': 3.1722, 'grad_norm': 10.031964302062988, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.77}\n",
      "{'loss': 3.1574, 'grad_norm': 9.295456886291504, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.77}\n",
      "{'loss': 3.1815, 'grad_norm': 8.599817276000977, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.78}\n",
      "{'loss': 3.1519, 'grad_norm': 8.405500411987305, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.78}\n",
      "{'loss': 3.187, 'grad_norm': 10.332104682922363, 'learning_rate': 1.25e-05, 'epoch': 0.79}\n",
      " 75%|██████████████████████████▎        | 22500/30000 [1:28:41<27:59,  4.47it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.28s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:15<00:05,  5.98s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 33.773592, 'eval_rouge-2': 7.959636, 'eval_rouge-l': 25.323794000000003, 'eval_bleu-4': 0.0370179972037972, 'eval_runtime': 32.3791, 'eval_samples_per_second': 1.544, 'eval_steps_per_second': 0.124, 'epoch': 0.79}\n",
      " 75%|██████████████████████████▎        | 22500/30000 [1:29:14<27:59,  4.47it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  4.56s/it]\u001b[A\n",
      "{'loss': 3.1404, 'grad_norm': 10.010290145874023, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.79}\n",
      "{'loss': 3.1319, 'grad_norm': 9.807190895080566, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.79}\n",
      "{'loss': 3.1949, 'grad_norm': 8.1905517578125, 'learning_rate': 1.2e-05, 'epoch': 0.8}\n",
      "{'loss': 3.1277, 'grad_norm': 10.210387229919434, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.8}\n",
      "{'loss': 3.1421, 'grad_norm': 9.007772445678711, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.8}\n",
      "{'loss': 3.1787, 'grad_norm': 9.395373344421387, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.81}\n",
      "{'loss': 3.1691, 'grad_norm': 9.005026817321777, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.81}\n",
      "{'loss': 3.1629, 'grad_norm': 11.29339599609375, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.81}\n",
      "{'loss': 3.1463, 'grad_norm': 9.865742683410645, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.82}\n",
      "{'loss': 3.175, 'grad_norm': 10.309219360351562, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.82}\n",
      "{'loss': 3.1452, 'grad_norm': 9.419913291931152, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.82}\n",
      "{'loss': 3.1886, 'grad_norm': 9.182723045349121, 'learning_rate': 1.05e-05, 'epoch': 0.83}\n",
      "{'loss': 3.1834, 'grad_norm': 10.771907806396484, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.83}\n",
      "{'loss': 3.1308, 'grad_norm': 9.413816452026367, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.83}\n",
      "{'loss': 3.1288, 'grad_norm': 10.597805976867676, 'learning_rate': 1e-05, 'epoch': 0.84}\n",
      " 80%|████████████████████████████       | 24000/30000 [1:34:39<22:27,  4.45it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:13<00:13,  6.78s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:27<00:09,  9.91s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.914152, 'eval_rouge-2': 7.755728, 'eval_rouge-l': 24.262676000000003, 'eval_bleu-4': 0.03709435351803895, 'eval_runtime': 45.061, 'eval_samples_per_second': 1.11, 'eval_steps_per_second': 0.089, 'epoch': 0.84}\n",
      " 80%|████████████████████████████       | 24000/30000 [1:35:24<22:27,  4.45it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:29<00:00,  6.79s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-24000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-24000/special_tokens_map.json\n",
      "{'loss': 3.1239, 'grad_norm': 10.061678886413574, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.84}\n",
      "{'loss': 3.1382, 'grad_norm': 9.131414413452148, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.84}\n",
      "{'loss': 3.2199, 'grad_norm': 8.998527526855469, 'learning_rate': 9.5e-06, 'epoch': 0.85}\n",
      "{'loss': 3.133, 'grad_norm': 9.023993492126465, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.85}\n",
      "{'loss': 3.1591, 'grad_norm': 9.549063682556152, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.86}\n",
      "{'loss': 3.1254, 'grad_norm': 9.972702026367188, 'learning_rate': 9e-06, 'epoch': 0.86}\n",
      "{'loss': 3.144, 'grad_norm': 10.49842357635498, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.86}\n",
      "{'loss': 3.1762, 'grad_norm': 8.862499237060547, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.87}\n",
      "{'loss': 3.161, 'grad_norm': 10.071542739868164, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.87}\n",
      "{'loss': 3.1638, 'grad_norm': 10.026422500610352, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.87}\n",
      "{'loss': 3.1369, 'grad_norm': 9.016655921936035, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.88}\n",
      "{'loss': 3.1424, 'grad_norm': 10.937761306762695, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.88}\n",
      "{'loss': 3.1494, 'grad_norm': 9.711747169494629, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.88}\n",
      "{'loss': 3.1738, 'grad_norm': 9.65941047668457, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.89}\n",
      "{'loss': 3.1532, 'grad_norm': 10.562475204467773, 'learning_rate': 7.5e-06, 'epoch': 0.89}\n",
      " 85%|█████████████████████████████▊     | 25500/30000 [1:40:55<16:26,  4.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.43s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 33.53236, 'eval_rouge-2': 7.783146, 'eval_rouge-l': 25.788562, 'eval_bleu-4': 0.0372527680789516, 'eval_runtime': 10.8763, 'eval_samples_per_second': 4.597, 'eval_steps_per_second': 0.368, 'epoch': 0.89}\n",
      " 85%|█████████████████████████████▊     | 25500/30000 [1:41:06<16:26,  4.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.70s/it]\u001b[A\n",
      "{'loss': 3.1288, 'grad_norm': 10.032942771911621, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.89}\n",
      "{'loss': 3.1604, 'grad_norm': 9.69816780090332, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.9}\n",
      "{'loss': 3.1471, 'grad_norm': 9.014467239379883, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 3.1837, 'grad_norm': 10.939640045166016, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.9}\n",
      "{'loss': 3.1453, 'grad_norm': 9.37083911895752, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.91}\n",
      "{'loss': 3.1325, 'grad_norm': 9.23774242401123, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.91}\n",
      "{'loss': 3.1932, 'grad_norm': 8.956214904785156, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.91}\n",
      "{'loss': 3.1584, 'grad_norm': 10.790550231933594, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.92}\n",
      "{'loss': 3.1665, 'grad_norm': 9.379403114318848, 'learning_rate': 6e-06, 'epoch': 0.92}\n",
      "{'loss': 3.2006, 'grad_norm': 9.832858085632324, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.92}\n",
      "{'loss': 3.1466, 'grad_norm': 11.349075317382812, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.93}\n",
      "{'loss': 3.1535, 'grad_norm': 9.609334945678711, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 3.1392, 'grad_norm': 9.871110916137695, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.94}\n",
      "{'loss': 3.122, 'grad_norm': 11.199357986450195, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.94}\n",
      "{'loss': 3.1616, 'grad_norm': 9.498676300048828, 'learning_rate': 5e-06, 'epoch': 0.94}\n",
      " 90%|███████████████████████████████▌   | 27000/30000 [1:46:34<10:36,  4.71it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.82s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:16<00:06,  6.45s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 33.189338, 'eval_rouge-2': 8.122198000000001, 'eval_rouge-l': 25.914390000000004, 'eval_bleu-4': 0.03837696447954937, 'eval_runtime': 22.5274, 'eval_samples_per_second': 2.22, 'eval_steps_per_second': 0.178, 'epoch': 0.94}\n",
      " 90%|███████████████████████████████▌   | 27000/30000 [1:46:57<10:36,  4.71it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:18<00:00,  4.69s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-27000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-27000/special_tokens_map.json\n",
      "{'loss': 3.1342, 'grad_norm': 9.666454315185547, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.95}\n",
      "{'loss': 3.1407, 'grad_norm': 10.01155948638916, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.95}\n",
      "{'loss': 3.1321, 'grad_norm': 10.286541938781738, 'learning_rate': 4.5e-06, 'epoch': 0.95}\n",
      "{'loss': 3.131, 'grad_norm': 10.009024620056152, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.96}\n",
      "{'loss': 3.153, 'grad_norm': 10.619215965270996, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.96}\n",
      "{'loss': 3.1515, 'grad_norm': 12.227978706359863, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.96}\n",
      "{'loss': 3.1134, 'grad_norm': 9.663722038269043, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.97}\n",
      "{'loss': 3.1555, 'grad_norm': 9.554591178894043, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.97}\n",
      "{'loss': 3.1204, 'grad_norm': 9.34001636505127, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.97}\n",
      "{'loss': 3.1176, 'grad_norm': 9.24498176574707, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.98}\n",
      "{'loss': 3.1014, 'grad_norm': 9.317843437194824, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.98}\n",
      "{'loss': 3.1601, 'grad_norm': 10.217525482177734, 'learning_rate': 3e-06, 'epoch': 0.98}\n",
      "{'loss': 3.1537, 'grad_norm': 11.810629844665527, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.99}\n",
      "{'loss': 3.1187, 'grad_norm': 9.95785140991211, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.99}\n",
      "{'loss': 3.1615, 'grad_norm': 10.151300430297852, 'learning_rate': 2.5e-06, 'epoch': 0.99}\n",
      " 95%|█████████████████████████████████▎ | 28500/30000 [1:52:27<05:43,  4.37it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.30s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.75s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.996221999999996, 'eval_rouge-2': 7.63717, 'eval_rouge-l': 25.360564000000004, 'eval_bleu-4': 0.03675185008347854, 'eval_runtime': 23.0466, 'eval_samples_per_second': 2.17, 'eval_steps_per_second': 0.174, 'epoch': 0.99}\n",
      " 95%|█████████████████████████████████▎ | 28500/30000 [1:52:50<05:43,  4.37it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:07<00:00,  1.84s/it]\u001b[A\n",
      "{'loss': 3.1435, 'grad_norm': 10.851890563964844, 'learning_rate': 2.3333333333333336e-06, 'epoch': 1.0}\n",
      "{'loss': 3.1134, 'grad_norm': 10.042054176330566, 'learning_rate': 2.166666666666667e-06, 'epoch': 1.0}\n",
      "{'loss': 3.1322, 'grad_norm': 9.963356018066406, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.01}\n",
      "{'loss': 3.1115, 'grad_norm': 9.53222942352295, 'learning_rate': 1.8333333333333335e-06, 'epoch': 1.01}\n",
      "{'loss': 3.0793, 'grad_norm': 10.219050407409668, 'learning_rate': 1.6666666666666667e-06, 'epoch': 1.01}\n",
      "{'loss': 3.123, 'grad_norm': 10.052590370178223, 'learning_rate': 1.5e-06, 'epoch': 1.02}\n",
      "{'loss': 3.0997, 'grad_norm': 9.902127265930176, 'learning_rate': 1.3333333333333334e-06, 'epoch': 1.02}\n",
      "{'loss': 3.084, 'grad_norm': 11.275967597961426, 'learning_rate': 1.1666666666666668e-06, 'epoch': 1.02}\n",
      "{'loss': 3.1069, 'grad_norm': 9.979484558105469, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1.03}\n",
      "{'loss': 3.1119, 'grad_norm': 9.366888999938965, 'learning_rate': 8.333333333333333e-07, 'epoch': 1.03}\n",
      "{'loss': 3.1558, 'grad_norm': 8.998619079589844, 'learning_rate': 6.666666666666667e-07, 'epoch': 1.03}\n",
      "{'loss': 3.0649, 'grad_norm': 9.672365188598633, 'learning_rate': 5.000000000000001e-07, 'epoch': 1.04}\n",
      "{'loss': 3.1411, 'grad_norm': 10.450902938842773, 'learning_rate': 3.3333333333333335e-07, 'epoch': 1.04}\n",
      "{'loss': 3.1286, 'grad_norm': 10.263570785522461, 'learning_rate': 1.6666666666666668e-07, 'epoch': 1.04}\n",
      "{'loss': 3.0957, 'grad_norm': 10.28285026550293, 'learning_rate': 0.0, 'epoch': 1.05}\n",
      "100%|███████████████████████████████████| 30000/30000 [1:58:20<00:00,  4.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:13<00:13,  6.50s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.53s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.882992, 'eval_rouge-2': 7.872908000000001, 'eval_rouge-l': 25.06591, 'eval_bleu-4': 0.037390401350964365, 'eval_runtime': 32.5338, 'eval_samples_per_second': 1.537, 'eval_steps_per_second': 0.123, 'epoch': 1.05}\n",
      "100%|███████████████████████████████████| 30000/30000 [1:58:52<00:00,  4.66it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  3.51s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-30000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-30000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 7133.6756, 'train_samples_per_second': 16.822, 'train_steps_per_second': 4.205, 'train_loss': 3.2231276041666668, 'epoch': 1.05}\n",
      "100%|███████████████████████████████████| 30000/30000 [1:58:53<00:00,  4.21it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [07:57<00:00,  7.13s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 /root/miniconda3/envs/LLM/bin/python3 finetune_hf.py  data/AdvertiseGen_fix  THUDM/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245998d9-5824-4a95-ae45-cc2c79bb2191",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "**训练时 显存占用情况**\n",
    "\n",
    "```bash\n",
    "Sat Mar 30 01:35:39 2024       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:2E:00.0 Off |                  Off |\n",
    "| 50%   72C    P2             416W / 450W |  21361MiB / 24564MiB |     93%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {},
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f22b735175e1c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T07:03:19.390123Z",
     "start_time": "2024-01-18T07:03:19.246666Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-30000\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T07:08:13.616364Z",
     "start_time": "2024-01-18T07:07:07.346906Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:04<00:00,  1.58it/s]\n",
      "这款连衣裙采用套头式的设计，简洁大气，方便穿脱。拼接压褶的设计，具有层次感，不规则的百褶裙摆，视觉上显瘦。前短后长的设计，尽显性感。腰间拉链，方便调节，简洁利落。木耳边点缀，精致优雅。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 /root/miniconda3/envs/LLM/bin/python3 inference_hf.py output/checkpoint-30000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
